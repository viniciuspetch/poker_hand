{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1. Introduction\n",
    "This first section will explain briefly the data set and some characteristics of the problem.\n",
    "\n",
    "This data set, named \"Poker Hand Data Set\", contains poker hands containing 5 cards (the same as \"horse poker\") and a class representing the value of the hand.\n",
    "\n",
    "The data set doesn't have missing values, and all features are categorical nominal. However, they're all represented by integer values, so changing for a better representation is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Numpy, Pandas, OS, MatPlotLib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn tools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Scikit-learn classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column names, read the datasets\n",
    "columns = [\"c1s\", \"c1n\", \"c2s\", \"c2n\", \"c3s\", \"c3n\", \"c4s\", \"c4n\", \"c5s\", \"c5n\", \"r\"]\n",
    "poker_db_train = pd.read_csv('poker-hand-training-true.data', names=columns)\n",
    "poker_db_test = pd.read_csv('poker-hand-testing.data', names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25010, 11)\n",
      "(1000000, 11)\n",
      "0    12493\n",
      "1    10599\n",
      "2     1206\n",
      "3      513\n",
      "4       93\n",
      "5       54\n",
      "6       36\n",
      "7        6\n",
      "9        5\n",
      "8        5\n",
      "Name: r, dtype: int64\n",
      "0    501209\n",
      "1    422498\n",
      "2     47622\n",
      "3     21121\n",
      "4      3885\n",
      "5      1996\n",
      "6      1424\n",
      "7       230\n",
      "8        12\n",
      "9         3\n",
      "Name: r, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print size of the training and test datasets\n",
    "print(poker_db_train.shape)\n",
    "print(poker_db_test.shape)\n",
    "print(poker_db_train['r'].value_counts())\n",
    "print(poker_db_test['r'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate classes from data sets\n",
    "x_train = poker_db_train.drop('r', axis=1)\n",
    "y_train = poker_db_train['r']\n",
    "x_test  = poker_db_test.drop('r', axis=1)\n",
    "y_test  = poker_db_test['r']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2. Raw simple test\n",
    "On this first section, I'll test the raw data set with some classification models. For each one, it'll be used the default configuration of each.\n",
    "\n",
    "To store the results, a dict `result_sect2` will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sect2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "result_sect2['knn'] = clf.score(x_test.iloc[0:1000], y_test.iloc[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)\n",
    "result_sect2['gaussian_nb'] = clf.score(x_test.iloc[0:1000], y_test.iloc[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn': 0.554, 'gaussian_nb': 0.508}\n"
     ]
    }
   ],
   "source": [
    "print(result_sect2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weights to the data, so that numbers and suits have different values\n",
    "def weightTransform(r, df, w, col_list):\n",
    "    if w != 1:\n",
    "        for i in col_list:\n",
    "            if w == 1:\n",
    "                r[i] = df[i]\n",
    "            else:\n",
    "                r[i] = df[i].transform(lambda x: x*w)\n",
    "\n",
    "def weightedData(df, w1=1, w2=1):\n",
    "    r = df.copy()\n",
    "    weightTransform(r, df, w1, ['c1n', 'c2n', 'c3n', 'c4n', 'c5n'])\n",
    "    weightTransform(r, df, w2, ['c1s', 'c2s', 'c3s', 'c4s', 'c5s'])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-NN wrapper function\n",
    "def knn1(x_train, y_train, x_test, y_test, max_n = 10, p=2):\n",
    "    result = []\n",
    "    for i in range(1, max_n):\n",
    "        clf = KNeighborsClassifier(n_neighbors=i, p=p)\n",
    "        clf.fit(x_train, y_train)\n",
    "        result.append(clf.score(x_test.iloc[0:1000], y_test.iloc[0:1000]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i, weights='distance')\n",
    "    clf.fit(poker_db_train_x, poker_db_train_y)\n",
    "    print(clf.score(poker_db_test_x.iloc[0:10000], poker_db_test_y.iloc[0:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(1, 15):\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    clf.fit(poker_db_train_x, poker_db_train_y)\n",
    "    result.append(clf.score(poker_db_test_x.iloc[0:10000], poker_db_test_y.iloc[0:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result)\n",
    "plt.xlabel(\"Qt\")\n",
    "plt.ylabel(\"Result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=6)\n",
    "clf.fit(poker_db_train_x, poker_db_train_y)\n",
    "prediction = clf.predict(poker_db_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(poker_db_test_y.value_counts())\n",
    "cm = confusion_matrix(poker_db_test_y, prediction)\n",
    "for i in range(0, 10):\n",
    "    print(cm[i][i]/cm[i].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedData(x_train, 1.15, 9.123).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_w = x_test.copy()\n",
    "for i in ['c1n', 'c2n', 'c3n', 'c4n', 'c5n']:\n",
    "    x_test_w[i] = x_test[i].transform(lambda x: x/13*20)\n",
    "for i in ['c1s', 'c2s', 'c3s', 'c4s', 'c5s']:\n",
    "    x_test_w[i] = x_test[i].transform(lambda x: x/4*5)\n",
    "print(x_test_w.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for w in range(3, 10):\n",
    "    result = knn1(weightedData(x_train, w, 1), y_train, weightedData(x_test, w, 1), y_test)\n",
    "    print(result)\n",
    "    ax.plot(result, label=w)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = knn1(weightedData(x_train, 5, 1), y_train, weightedData(x_test, 5, 1), y_test)\n",
    "print(result)\n",
    "plt.plot(result, label='asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(result, label=\"asd\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1(x_train_w, y_train, x_test_w, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "enc = preprocessing.OneHotEncoder(categories='auto')\n",
    "x_train_onehot = pd.DataFrame(enc.fit_transform(x_train).toarray())\n",
    "x_test_onehot = pd.DataFrame(enc.fit_transform(x_test).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing k-nn with the one-hot encoded data set\n",
    "result = knn1(x_train_onehot, y_train, x_test_onehot, y_test)\n",
    "print(result)\n",
    "plt.plot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing k-nn with the one-hot encoded data set, and a different distance calculator\n",
    "result = knn1(x_train_onehot, y_train, x_test_onehot, y_test, p=1)\n",
    "print(result)\n",
    "plt.plot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort training values based on the number, using the suit as tiebreaker\n",
    "x_train_sorted = x_train.copy().sample(frac=1).reset_index(drop=True)\n",
    "for i in range(0 , x_train_sorted.shape[0]):\n",
    "    for j in range(0, 8, 2):        \n",
    "        p = j\n",
    "        while p >= 0 and (x_train_sorted.iloc[i][p+1] > x_train_sorted.iloc[i][p+3] or (x_train_sorted.iloc[i][p+1] == x_train_sorted.iloc[i][p+3] and x_train_sorted.iloc[i][p+0] > x_train_sorted.iloc[i][p+2])):\n",
    "            aux = x_train_sorted.iloc[i][p+1]\n",
    "            x_train_sorted.iloc[i][p+1] = x_train_sorted.iloc[i][p+3]\n",
    "            x_train_sorted.iloc[i][p+3] = aux\n",
    "            \n",
    "            aux = x_train_sorted.iloc[i][p+0]\n",
    "            x_train_sorted.iloc[i][p+0] = x_train_sorted.iloc[i][p+2]\n",
    "            x_train_sorted.iloc[i][p+2] = aux\n",
    "            p -= 2\n",
    "            \n",
    "x_train_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort test values based on the number, using the suit as tiebreaker\n",
    "x_test_sorted = x_test.copy().sample(frac=1).reset_index(drop=True)\n",
    "for i in range(0 , 10000):\n",
    "    for j in range(0, 8, 2):        \n",
    "        p = j\n",
    "        while p >= 0 and (x_test_sorted.iloc[i][p+1] > x_test_sorted.iloc[i][p+3] or (x_test_sorted.iloc[i][p+1] == x_test_sorted.iloc[i][p+3] and x_test_sorted.iloc[i][p+0] > x_test_sorted.iloc[i][p+2])):\n",
    "            aux = x_test_sorted.iloc[i][p+1]\n",
    "            x_test_sorted.iloc[i][p+1] = x_test_sorted.iloc[i][p+3]\n",
    "            x_test_sorted.iloc[i][p+3] = aux\n",
    "            \n",
    "            aux = x_test_sorted.iloc[i][p+0]\n",
    "            x_test_sorted.iloc[i][p+0] = x_test_sorted.iloc[i][p+2]\n",
    "            x_test_sorted.iloc[i][p+2] = aux\n",
    "            p -= 2\n",
    "            \n",
    "x_test_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing k-nn with the sorted data sets\n",
    "result = knn1(x_train_sorted, y_train, x_test_sorted, y_test)\n",
    "print(result)\n",
    "plt.plot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing MLP\n",
    "\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(30,10), random_state=1, max_iter=1000)\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5 5): 0.555000\n",
      "(5 8): 0.571000\n",
      "(5 11): 0.591000\n",
      "(5 14): 0.577000\n",
      "(5 17): 0.596000\n",
      "(5 20): 0.631000\n",
      "(5 23): 0.618000\n",
      "(5 26): 0.689000\n",
      "(5 29): 0.578000\n",
      "(5 32): 0.617000\n",
      "(5 35): 0.554000\n",
      "(5 38): 0.575000\n",
      "(5 41): 0.625000\n",
      "(5 44): 0.664000\n",
      "(5 47): 0.746000\n",
      "(8 5): 0.559000\n",
      "(8 8): 0.576000\n",
      "(8 11): 0.550000\n",
      "(8 14): 0.576000\n",
      "(8 17): 0.560000\n",
      "(8 20): 0.577000\n",
      "(8 23): 0.656000\n",
      "(8 26): 0.588000\n",
      "(8 29): 0.684000\n",
      "(8 32): 0.641000\n",
      "(8 35): 0.620000\n",
      "(8 38): 0.624000\n",
      "(8 41): 0.818000\n",
      "(8 44): 0.758000\n",
      "(8 47): 0.700000\n",
      "(11 5): 0.596000\n",
      "(11 8): 0.587000\n",
      "(11 11): 0.589000\n",
      "(11 14): 0.627000\n",
      "(11 17): 0.668000\n",
      "(11 20): 0.689000\n",
      "(11 23): 0.679000\n",
      "(11 26): 0.662000\n",
      "(11 29): 0.641000\n",
      "(11 32): 0.689000\n",
      "(11 35): 0.724000\n",
      "(11 38): 0.740000\n",
      "(11 41): 0.706000\n",
      "(11 44): 0.829000\n",
      "(11 47): 0.687000\n",
      "(14 5): 0.607000\n",
      "(14 8): 0.645000\n",
      "(14 11): 0.615000\n",
      "(14 14): 0.599000\n",
      "(14 17): 0.727000\n",
      "(14 20): 0.623000\n",
      "(14 23): 0.689000\n",
      "(14 26): 0.742000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14 29): 0.854000\n",
      "(14 32): 0.739000\n",
      "(14 35): 0.777000\n",
      "(14 38): 0.777000\n",
      "(14 41): 0.668000\n",
      "(14 44): 0.718000\n",
      "(14 47): 0.728000\n",
      "(17 5): 0.635000\n",
      "(17 8): 0.577000\n",
      "(17 11): 0.607000\n",
      "(17 14): 0.677000\n",
      "(17 17): 0.661000\n",
      "(17 20): 0.728000\n",
      "(17 23): 0.693000\n",
      "(17 26): 0.777000\n",
      "(17 29): 0.696000\n",
      "(17 32): 0.700000\n",
      "(17 35): 0.806000\n",
      "(17 38): 0.914000\n",
      "(17 41): 0.732000\n",
      "(17 44): 0.759000\n",
      "(17 47): 0.714000\n",
      "(20 5): 0.644000\n",
      "(20 8): 0.672000\n",
      "(20 11): 0.610000\n",
      "(20 14): 0.699000\n",
      "(20 17): 0.703000\n",
      "(20 20): 0.783000\n",
      "(20 23): 0.894000\n",
      "(20 26): 0.751000\n",
      "(20 29): 0.726000\n",
      "(20 32): 0.783000\n",
      "(20 35): 0.836000\n",
      "(20 38): 0.954000\n",
      "(20 41): 0.985000\n",
      "(20 44): 0.987000\n",
      "(20 47): 0.902000\n",
      "(23 5): 0.611000\n",
      "(23 8): 0.591000\n",
      "(23 11): 0.747000\n",
      "(23 14): 0.760000\n",
      "(23 17): 0.764000\n",
      "(23 20): 0.777000\n",
      "(23 23): 0.743000\n",
      "(23 26): 0.759000\n",
      "(23 29): 0.755000\n",
      "(23 32): 0.842000\n",
      "(23 35): 0.801000\n",
      "(23 38): 0.764000\n",
      "(23 41): 0.843000\n",
      "(23 44): 0.879000\n",
      "(23 47): 0.779000\n",
      "(26 5): 0.720000\n",
      "(26 8): 0.736000\n",
      "(26 11): 0.708000\n",
      "(26 14): 0.832000\n",
      "(26 17): 0.813000\n",
      "(26 20): 0.839000\n",
      "(26 23): 0.865000\n",
      "(26 26): 0.774000\n",
      "(26 29): 0.958000\n",
      "(26 32): 0.819000\n",
      "(26 35): 0.989000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26 38): 0.957000\n",
      "(26 41): 0.859000\n",
      "(26 44): 0.862000\n",
      "(26 47): 0.939000\n",
      "(29 5): 0.677000\n",
      "(29 8): 0.685000\n",
      "(29 11): 0.784000\n",
      "(29 14): 0.675000\n",
      "(29 17): 0.784000\n",
      "(29 20): 0.983000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29 23): 0.960000\n",
      "(29 26): 0.969000\n",
      "(29 29): 0.799000\n",
      "(29 32): 0.787000\n",
      "(29 35): 0.847000\n",
      "(29 38): 0.813000\n",
      "(29 41): 0.838000\n",
      "(29 44): 0.985000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29 47): 0.970000\n",
      "(32 5): 0.654000\n",
      "(32 8): 0.705000\n",
      "(32 11): 0.791000\n",
      "(32 14): 0.750000\n",
      "(32 17): 0.745000\n",
      "(32 20): 0.779000\n",
      "(32 23): 0.976000\n",
      "(32 26): 0.934000\n",
      "(32 29): 0.922000\n",
      "(32 32): 0.985000\n",
      "(32 35): 0.873000\n"
     ]
    }
   ],
   "source": [
    "for i in range(5, 50, 3):\n",
    "    for j in range(5, 50, 3):\n",
    "        clf = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(i,j), random_state=1, max_iter=1000)\n",
    "        clf.fit(x_train, y_train)\n",
    "        print(\"(%d %d): %f\" % (i, j, clf.score(x_test[:1000], y_test[:1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(10, 5))\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf.score(x_test[:1000], y_test[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
